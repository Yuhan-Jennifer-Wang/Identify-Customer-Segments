```{r}
setwd('d:/Columbia/AA/framework2/project')
azdias = read.csv('Udacity_AZDIAS_Subset.csv',sep = ';')
feature_info = read.csv('AZDIAS_Feature_Summary.csv', sep = ';')
azdias_copy = azdias
```
```{r}
str(azdias)
```
```{r}
feature_info
```
```{r}
# identify missing values in columns and convert to NA
library(stringr)
na_list = sapply(1:85, function(x) feature_info[x,4])
na_list = as.character(na_list)
na_list= gsub('\\[','',na_list)
na_list = gsub('\\]','',na_list)
na_list = str_split(na_list, ",") 

for (i in 1:85){
  print(i)
  na_code = as.list(na_list[[i]])
  print(na_code)
  for (na in na_code){
    if (na == ""){
      next
    }
    else if (class(na)== "character"){
      print(na)
      azdias_copy[azdias_copy[,i] %in% c(na,""),i] = NA
    } else{
      na = as.integer(na)
      print(na)
      azdias_copy[azdias_copy[,i] %in% c(na,""),i] = NA
    }
  }
}

sum(is.na(azdias_copy))
```

```{r}
missingdata_column = lapply(1:85, function(x) sum(is.na(azdias_copy[,x])))##colSums(is.na(df))
col_name = colnames(azdias_copy);
missingdata_c = as.data.frame(missingdata_column,col.names = col_name)
missingdata_c
write.csv(missingdata_c,file="d:/¸ç´ó/AA/framework2/project/missing",quote=F,row.names = F)

```
```{r}
missingdata_c = t(missingdata_c)
colnames(missingdata_c) = c("missingcount")
missingdata_c = as.data.frame(missingdata_c)
missingdata_c
```
```{r}
library(ggplot2)
ggplot(missingdata_c, aes(x = missingcount))+
  geom_histogram()
```
```{r}
# identify columns with missing values greater than 250000
which(missingdata_c$missingcount>250000)
```
```{r}
#drop column that has missing data more than 20% .GER_TYP ,GEBURTSJAHR, TITEL_KZ,ANZ_TITEL,KK_KUNDENTYP,ALTER_HH,KBA05_BAUMAX
library(dplyr)
azdias_copy = select(azdias_copy,-c(1, 12, 41, 44, 48, 65))
feature_info = feature_info[-c(1, 12, 41, 44, 48, 65),]
str(azdias_copy)
```
```{r}
# calculate na in rows
missingdata_rows = lapply(1:891221, function(x) sum(is.na(azdias_copy[x,])))

```
```{r}
missingdata_r = as.data.frame(missingdata_rows)
missingdata_r = t(missingdata_r)
missingdata_r
colnames(missingdata_r) = c("missingcount")
azdias_copy = cbind(azdias_copy,missingdata_r)
str(azdias_copy)
write.csv(azdias_copy,file="d:/Columbia/AA/framework2/project/missing_row_count.csv",quote=F,row.names = F)

```
```{r}
ggplot(azdias_copy, aes(x=missingcount))+
  geom_histogram()
```
```{r}
# Write code to divide the data into two subsets based on the number of missing values in each row.
azdias1 = azdias_copy[azdias_copy$missingcount<=5,]
azdias2 = azdias_copy[azdias_copy$missingcount>5,]
azdias1 = select(azdias1,-c(missingcount))
nrow(azdias1)
str(azdias1)
```
```{r}
# Compare the distribution of values for at least five columns where there are no or few missing values, between the two subsets. 
# not working for now
compareplot <- function(column_name){
  ggplot(azdias1,aes_string(x=column_name))+
    geom_bar()+
    title("azdias1")
  ggplot(azdias2,aes_string(x=column_name))+
    geom_bar()+
    title("azdias2")
}
compareplot(colnames(azdias1)[1])
colnames(azdias1)[1]
# compare by hand
ggplot(azdias1,aes(x=ANREDE_KZ))+
  geom_bar(binwidth = 0.5)
```
```{r}
#process categorical features & mixed type features, numeric and ordinal are fine
table(feature_info$type)
```
```{r}
feature_info[feature_info$type == 'categorical',]
```
```{r}
# look into categorical features
for (i in feature_info[feature_info$type == 'categorical','attribute']){
  plt = ggplot(azdias1,aes_string(x=i))+
    geom_bar()
  print(plt)
}
```
```{r}
#transfer to dummy variable 'CJT_GESAMTTYP', 'FINANZTYP','LP_FAMILIE_GROB', 'LP_STATUS_GROB', #'NATIONALITAET_KZ', 'SHOPPER_TYP', 'ZABEOTYP', 'OST_WEST_KZ' 
install.packages('fastDummies')
library(fastDummies)
azdias1_oh = dummy_cols(azdias1, select_columns = c('CJT_GESAMTTYP','FINANZTYP', 'LP_FAMILIE_GROB', 'LP_STATUS_GROB', 'NATIONALITAET_KZ', 'SHOPPER_TYP', 'ZABEOTYP', 'OST_WEST_KZ'))
str(azdias1_oh)
azdias1_oh = select(azdias1_oh, -c('CJT_GESAMTTYP','FINANZTYP', 'LP_FAMILIE_GROB', 'LP_STATUS_GROB', 'NATIONALITAET_KZ', 'SHOPPER_TYP', 'ZABEOTYP', 'OST_WEST_KZ'))
#LP_FAMILIE_GROB_NA,NATIONALITAET_KZ_NA,SHOPPER_TYP_NA                         
```
```{r}
#drop features that have too many levels 'GFK_URLAUBERTYP', 'LP_FAMILIE_FEIN', 'LP_STATUS_FEIN', 'GEBAEUDETYP', 'CAMEO_DEUG_2015', 'CAMEO_DEU_2015'
azdias1_oh = select(azdias1_oh, -c('GFK_URLAUBERTYP', 'LP_FAMILIE_FEIN', 'LP_STATUS_FEIN', 'GEBAEUDETYP', 'CAMEO_DEUG_2015', 'CAMEO_DEU_2015'))
str(azdias1_oh)

```
```{r}
# process mixed type features
# change PRAEGENDE_JUGENDJAHRE into 3 new variables, decades, region, and movement
create_newfeature1 = function(azdias1_oh){
  azdias1_oh$movement[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(1,3,5,8,10,12,14)] = 'MainStream'
  azdias1_oh$movement[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(2,4,6,7,9,11,13,15)] = 'Avantgarde'
  # create second new varibale: 'Region': East, West, EAST+WEST
  azdias1_oh$region[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(7,12,13)] = 'E'
  azdias1_oh$region[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(6,10,11)] = 'W'
  azdias1_oh$region[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(1,2,3,4,5,8,9,14,15)] = 'E+W'
  # create second new varibale: 'decades': 40ies, 50ies, 60ies, 70ies, 80-ies, 90ies
  azdias1_oh$decades[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(1,2)] = '40s'
  azdias1_oh$decades[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(3,4)] = '50s'
  azdias1_oh$decades[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(5,6,7)] = '60s'
  azdias1_oh$decades[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(8,9)] = '70s'
  azdias1_oh$decades[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(10,11,12,13)] = '80s'
  azdias1_oh$decades[azdias1_oh$PRAEGENDE_JUGENDJAHRE %in% c(14,15)] = '90s'
  return(azdias1_oh)
}

azdias1_oh = create_newfeature1(azdias1_oh)
str(azdias1_oh)

# One-hot encode the 3 new features
azdias1_oh = dummy_cols(azdias1_oh, select_columns = c('movement','region','decades'))
# drop original column
azdias1_oh = select(azdias1_oh,-c(PRAEGENDE_JUGENDJAHRE,movement,region,decades))
str(azdias1_oh)
```
```{r}
# change "CAMEO_INTL_2015" nto two new variables,household_wealth and life_stage

create_newfeature2 = function(azdias1_oh){
  # create first new varibale: 'household_wealth',poor, less_affluent, comfortable, prosperous, wealthy
  azdias1_oh$household_wealth[azdias1_oh$CAMEO_INTL_2015 %in% c(51,52,53,54,55)] = 'poor'
  azdias1_oh$household_wealth[azdias1_oh$CAMEO_INTL_2015 %in% c(41,42,43,44,45)] = 'less_affluent'
  azdias1_oh$household_wealth[azdias1_oh$CAMEO_INTL_2015 %in% c(31,32,33,34,35)] = 'comfortable'
  azdias1_oh$household_wealth[azdias1_oh$CAMEO_INTL_2015 %in% c(21,22,23,24,25)] = 'prosperous'
  azdias1_oh$household_wealth[azdias1_oh$CAMEO_INTL_2015 %in% c(11,12,13,14,15)] = 'wealthy'
  # create second new varibale: 'life_stage',Pre-Family Couples & Singles, Young Couples With Children, Families With School Age Children, Older Families &  Mature Couples, Elders In Retirement
  azdias1_oh$life_stage[azdias1_oh$CAMEO_INTL_2015 %in% c(11,21,31,41,51)] = 'Pre-Family Couples & Singles'
  azdias1_oh$life_stage[azdias1_oh$CAMEO_INTL_2015 %in% c(12,22,32,42,52)] = 'Young Couples With Children'
  azdias1_oh$life_stage[azdias1_oh$CAMEO_INTL_2015 %in% c(13,23,33,43,53)] = 'Families With School Age Children'
  azdias1_oh$life_stage[azdias1_oh$CAMEO_INTL_2015 %in% c(14,24,34,44,54)] = 'Older Families &  Mature Couples'
  azdias1_oh$life_stage[azdias1_oh$CAMEO_INTL_2015 %in% c(15,25,35,45,55)] = 'Elders In Retirement'
  return(azdias1_oh)
}

azdias1_oh = create_newfeature2(azdias1_oh)

str(azdias1_oh)
# One-hot encode the 2 new features
azdias1_oh = dummy_cols(azdias1_oh, select_columns = c('household_wealth','life_stage'))
# drop original column
azdias1_oh = select(azdias1_oh,-c(CAMEO_INTL_2015,household_wealth,life_stage))
#str(azdias1_oh)
```
```{r}
# Drop Other Features 'LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB', 'WOHNLAGE', 'PLZ8_BAUMAX'
azdias1_oh = select(azdias1_oh, -c(LP_LEBENSPHASE_FEIN,LP_LEBENSPHASE_GROB,WOHNLAGE,PLZ8_BAUMAX))
#str(azdias1_oh)

```

```{r}
#check na values
null_list = colSums(is.na(azdias1_oh))
null_per = null_list / nrow(azdias1_oh) * 100
hist(null_per)
```
```{r}
# impute missing values with median
library(caret)
azdias1_impute = predict(preProcess(azdias1_oh,method = 'medianImpute'),newdata = azdias1_oh) 
write.csv(azdias1_impute,file="d:/Columbia/AA/framework2/project/azdias1_impute.csv",quote=F,row.names = F)
azdias1_impute = read.csv("azdias1_impute.csv")

#use PCA
library(FactoMineR)
pca_facto = PCA(azdias1_impute,graph = F)
library(factoextra)
fviz_eig(pca_facto,ncp=125,addlabels = T)
```
```{r}
#check variance explained, and I select 77 pc
pca_facto$eig
get_eigenvalue(pca_facto)

```
```{r}
#run with 77 pc
pca_facto = PCA(azdias1_impute,scale.unit = T,ncp = 77,graph = F)
```
```{r}
#print result
print(pca_facto)
```
```{r}
#check weights for variables
var <- get_pca_var(pca_facto)
var
sort(var$cor[,1]) ## weights for variables, pc1,  
#FINANZ_MINIMALIST, most negtive corelated,
#LP_STATUS_GROB_1, most positive corelated
```
```{r}
sort(var$cor[,2])
#ALTERSKATEGORIE_GROB, most negtive corelated,
#SEMIO_REL, most positive corelated
```
```{r}
sort(var$cor[,3])
#SEMIO_VERT, most negtive corelated,
#ANREDE_KZ, most positive corelated
```
```{r}
#use pca coordinates for the original data
pca_facto$ind$coord
ind_coord = as.data.frame(pca_facto$ind$coord)
pca_df = ind_coord
pca_df = round(pca_df,2)
head(pca_df)
str(pca_df)
write.csv(pca_df,file="d:/Columbia/AA/framework2/project/pca_df.csv",quote=F,row.names = F)
pca_df = as.matrix(pca_df)
dim(pca_df)
pca_df = as.data.frame(pca_df)
#pca_df = read.csv("pca_df.csv",sep = ';')
```

```{r}
#visulization
fviz_pca_var(pca_facto, axes = c(1,1), col.var = "contrib", 
  select.var = list(contrib = 5), gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),col.circle = 'steelblue',repel = T)
```
```{r}
fviz_pca_var(pca_facto, axes = c(2,2), col.var = "contrib", 
  select.var = list(contrib = 5), gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),col.circle = 'steelblue',repel = T)
```


```{r}
# kmeans, choose number of clusters
within_ss_1 = kmeans(x = pca_df,centers = 1,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_1
within_ss_2 = kmeans(x = pca_df,centers = 2,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_2
within_ss_3 = kmeans(x = pca_df,centers = 3,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_3
within_ss_4 = kmeans(x = pca_df,centers = 4,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_4
within_ss_5 = kmeans(x = pca_df,centers = 5,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_5
within_ss_6 = kmeans(x = pca_df,centers = 6,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_6
within_ss_7 = kmeans(x = pca_df,centers = 7,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_7
within_ss_8 = kmeans(x = pca_df,centers = 8,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_8
within_ss_9 = kmeans(x = pca_df,centers = 9,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_9
within_ss_10 = kmeans(x = pca_df,centers = 10,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_10
within_ss_11 = kmeans(x = pca_df,centers = 11,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_11
within_ss_12 = kmeans(x = pca_df,centers = 12,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_12
within_ss_13 = kmeans(x = pca_df,centers = 13,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_13
within_ss_14 = kmeans(x = pca_df,centers = 14,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_14
within_ss_15 = kmeans(x = pca_df,centers = 15,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_15
within_ss_16 = kmeans(x = pca_df,centers = 16,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_16
within_ss_17 = kmeans(x = pca_df,centers = 17,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_17
within_ss_18 = kmeans(x = pca_df,centers = 18,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_18
within_ss_19 = kmeans(x = pca_df,centers = 19,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_19
within_ss_20 = kmeans(x = pca_df,centers = 20,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_20
within_ss_21 = kmeans(x = pca_df,centers = 21,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_21
within_ss_22 = kmeans(x = pca_df,centers = 22,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_22
within_ss_23 = kmeans(x = pca_df,centers = 23,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_23
within_ss_24 = kmeans(x = pca_df,centers = 24,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_24
within_ss_25 = kmeans(x = pca_df,centers = 25,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_25
within_ss_26 = kmeans(x = pca_df,centers = 26,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_26
within_ss_27 = kmeans(x = pca_df,centers = 27,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_27
within_ss_28 = kmeans(x = pca_df,centers = 28,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_28
within_ss_29 = kmeans(x = pca_df,centers = 29,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_29
within_ss_30 = kmeans(x = pca_df,centers = 30,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_30
within_ss_31 = kmeans(x = pca_df,centers = 31,iter.max = 1000,nstart = 25)$tot.withinss;within_ss_31


within_ss = c(within_ss_1,within_ss_2,within_ss_3,within_ss_4,within_ss_5,within_ss_6,within_ss_7,within_ss_8,within_ss_9,within_ss_10,within_ss_11,within_ss_12,within_ss_13,within_ss_14,within_ss_15,within_ss_16,within_ss_17,within_ss_18,within_ss_19,within_ss_20,within_ss_21,within_ss_22,within_ss_23,within_ss_24,within_ss_25,within_ss_26,within_ss_27,within_ss_28)
within_ss
ggplot(data=data.frame(cluster = 1:28,within_ss),aes(x=cluster,y=within_ss))+
  geom_line(col='steelblue',size=1.2)+
  geom_point()+
  scale_x_continuous(breaks=seq(1,28,1))
```
```{r}
set.seed(617)
# choose 16 clusters based on previous visulization
km = kmeans(x = pca_df,centers = 16,iter.max=10000,nstart=25)
k_segments = km$cluster
table(k_segments)
```
```{r}
```
```{r}
#clean customer data
customers = read.csv('Udacity_CUSTOMERS_Subset.csv', sep = ';')
customers_copy = customers

# identify missing values in columns and convert to NA

for (i in 1:85){
  print(i)
  na_code = as.list(na_list[[i]])
  print(na_code)
  for (na in na_code){
    if (na == ""){
      next
    }
    else if (class(na)== "character"){
      print(na)
      customers_copy[customers_copy[,i] %in% c(na,""),i] = NA
    } else{
      na = as.integer(na)
      print(na)
      customers_copy[customers_copy[,i] %in% c(na,""),i] = NA
    }
  }
}
#drop the same column as in azdias
customers_copy = select(customers_copy,-c(1, 12, 41, 44, 48, 65))
# missingdata in rows
missingdata_rows_customer = lapply(1:191652, function(x) sum(is.na(customers_copy[x,])))
missingdata_r_customer = as.data.frame(missingdata_rows_customer)
missingdata_r_customer = t(missingdata_r_customer)
colnames(missingdata_r_customer) = c("missingcount")
customers_copy = cbind(customers_copy,missingdata_r_customer)
# drop rows that have missing values more than 5
customer_1 = customers_copy[customers_copy$missingcount<=5,]
customer_2 = customers_copy[customers_copy$missingcount>5,]
customer_1 = select(customer_1,-c(missingcount))
```
```{r}
#transfer to dummy variable 'CJT_GESAMTTYP', 'FINANZTYP','LP_FAMILIE_GROB', 'LP_STATUS_GROB', #'NATIONALITAET_KZ', 'SHOPPER_TYP', 'ZABEOTYP', 'OST_WEST_KZ' 
library(fastDummies)
customer_oh = dummy_cols(customer_1, select_columns = c('CJT_GESAMTTYP','FINANZTYP', 'LP_FAMILIE_GROB', 'LP_STATUS_GROB', 'NATIONALITAET_KZ', 'SHOPPER_TYP', 'ZABEOTYP', 'OST_WEST_KZ'))
str(customer_oh)
customer_oh = select(customer_oh, -c('CJT_GESAMTTYP','FINANZTYP', 'LP_FAMILIE_GROB', 'LP_STATUS_GROB', 'NATIONALITAET_KZ', 'SHOPPER_TYP', 'ZABEOTYP', 'OST_WEST_KZ'))
#LP_FAMILIE_GROB_NA,NATIONALITAET_KZ_NA,SHOPPER_TYP_NA      

#drop features that have too many levels 'GFK_URLAUBERTYP', 'LP_FAMILIE_FEIN', 'LP_STATUS_FEIN', 'GEBAEUDETYP', 'CAMEO_DEUG_2015', 'CAMEO_DEU_2015'
customer_oh = select(customer_oh, -c('GFK_URLAUBERTYP', 'LP_FAMILIE_FEIN', 'LP_STATUS_FEIN', 'GEBAEUDETYP', 'CAMEO_DEUG_2015', 'CAMEO_DEU_2015'))
```
```{r}
#re-engineering feature
customer_oh = create_newfeature1(customer_oh)

# One-hot encode the 3 new features
customer_oh = dummy_cols(customer_oh, select_columns = c('movement','region','decades'))
# drop original column
customer_oh = select(customer_oh,-c(PRAEGENDE_JUGENDJAHRE,movement,region,decades))
# drop original column
customers_copy = select(customers_copy,-c(PRAEGENDE_JUGENDJAHRE))

customer_oh = create_newfeature2(customer_oh)
# One-hot encode the 2 new features
customer_oh = dummy_cols(customer_oh, select_columns = c('household_wealth','life_stage'))
# drop original column
customer_oh = select(customer_oh,-c(CAMEO_INTL_2015,household_wealth,life_stage))
```
```{r}
# Drop Other Features 'LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB', 'WOHNLAGE', 'PLZ8_BAUMAX'
customer_oh = select(customer_oh, -c(LP_LEBENSPHASE_FEIN,LP_LEBENSPHASE_GROB,WOHNLAGE,PLZ8_BAUMAX))
str(customer_oh)
```
```{r}
null_list_c = colSums(is.na(customer_oh))
null_per_c = null_list_c / nrow(customer_oh) * 100
hist(null_per_c)
write.csv(customer_oh,file="d:/Columbia/AA/framework2/project/customer_oh.csv",quote=F,row.names = F)

```
```{r}

```
```{r}
# impute missing value 
customers_impute = predict(preProcess(customer_oh,method = 'medianImpute'),newdata = customer_oh) 
write.csv(customers_impute,file="d:/Columbia/AA/framework2/project/customers_impute.csv",quote=F,row.names = F)
```

```{r}
# change col_name to be same as azdias data, to apply pca
names(customers_impute)[names(customers_impute)=="life_stage_Families With School Age Children"] = "life_stage_Families.With.School.Age.Children";
names(customers_impute)[names(customers_impute)=="life_stage_Older Families &  Mature Couples"] = "life_stage_Older.Families....Mature.Couples";
names(customers_impute)[names(customers_impute)=="life_stage_Pre-Family Couples & Singles"] = "life_stage_Pre.Family.Couples...Singles";
names(customers_impute)[names(customers_impute)=="life_stage_Elders In Retirement"] = "life_stage_Elders.In.Retirement";
names(customers_impute)[names(customers_impute)=="life_stage_Young Couples With Children"] = "life_stage_Young.Couples.With.Children";
names(customers_impute)[names(customers_impute)=="region_E+W"] = "region_E.W";
write.csv(customers_impute,file="d:/Columbia/AA/framework2/project/customers_impute1.csv",quote=F,row.names = F)

```
```{r}
#apply pca on customer data
pca_customer = predict(pca_facto, newdata = customers_impute)
pca_cus = pca_customer$coord
class(pca_cus)
```
```{r}
#apply kmeans clusters on customer data
km$centers
closest.cluster <- function(x) {
  cluster.dist <- apply(km$centers, 1, function(y) sqrt(sum((x-y)^2)))
  return(which.min(cluster.dist)[1])
}
clusters_cus <- apply(pca_cus, 1, closest.cluster)
clusters_cus
#customer distribution
table(clusters_cus)
dist_cus = table(clusters_cus)
dist_cus = dist_cus/nrow(customers_impute)*100
dist_cus
```
```{r}
dist_c = data.frame(dist_cus)
colnames(dist_c)=c('cluster','freq')
dist_c
ggplot(dist_c,aes(cluster,freq))+
  geom_bar(stat = 'identity')
```
```{r}
#general population distribution
dist_az = table(km$cluster)
dist_az = dist_az/nrow(azdias1_impute)*100
dist_az
```
```{r}
dist_a = data.frame(dist_az)
colnames(dist_a)=c('cluster','freq')
ggplot(dist_a,aes(cluster,freq))+
  geom_bar(stat = 'identity')
```
```{r}
#compare distribution
compare = data.frame(freq_az=dist_az,freq_customer=dist_cus)
compare = select(compare,-freq_customer.clusters_cus)
compare
colnames(compare)=c('cluster','freq_az','freq_customer')
compare%>%
  gather
ggplot(dist_a,aes(cluster,fill=cluster))+
  geom_bar(stat = 'identity')
```
```{r}

```
```{r}

```
```{r}
```
```{r}
```
```{r}
```
```{r}

```